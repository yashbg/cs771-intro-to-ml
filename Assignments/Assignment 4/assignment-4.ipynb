{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use any additional libraries you want, but if you don't explicitly code stuff that I have explicitly asked you to code, you will not get marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Kernel k-means\n",
    "\n",
    "Let's try and end our course on a happy note. The smiley dataset you see below is made up of many clusters of points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import numpy.random as rnd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def getFigure( sizex = 7, sizey = 7 ):\n",
    "    fig = plt.figure( figsize = (sizex, sizey) )\n",
    "    return fig\n",
    "\n",
    "def plot2D( X, fig, color = 'r', marker = '+', size = 100, empty = False ):\n",
    "    plt.figure( fig.number )\n",
    "    if empty:\n",
    "        plt.scatter( X[:,0], X[:,1], s = size, facecolors = 'none', edgecolors = color, marker = marker  )\n",
    "    else:\n",
    "        plt.scatter( X[:,0], X[:,1], s = size, c = color, marker = marker )\n",
    "\n",
    "\n",
    "def genCrescentData( d, n, mu, r, flipped = False ):\n",
    "    X = np.vstack( (np.cos( np.linspace( 0, np.pi, n ) ), np.sin( np.linspace( 0, np.pi, n ) ) ) ).T\n",
    "    if flipped:\n",
    "        X[:,1] = -np.abs( X[:,1] )\n",
    "    else:\n",
    "        X[:,1] = np.abs( X[:,1] )\n",
    "    X = (X * r) + mu\n",
    "    return X\n",
    "\n",
    "def genSphericalData( d, n, mu, r ):\n",
    "    X = rnd.normal( 0, 1, (n, d) )\n",
    "    norms = lin.norm( X, axis = 1 )\n",
    "    X = X / norms[:, np.newaxis]\n",
    "    X = (X * r) + mu\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "n = 200\n",
    "\n",
    "mu1 = np.array( [0,0] )\n",
    "mu2 = np.array( [0,1] )\n",
    "mu3 = np.array( [0,0] )\n",
    "mu4 = np.array( [-3,5] )\n",
    "mu5 = np.array( [3,5] )\n",
    "\n",
    "tmp1 = genCrescentData( d, n, mu1, 1 )\n",
    "tmp2 = genCrescentData( d, n, mu2, 5, flipped = True )\n",
    "tmp3 = genSphericalData( d, n, mu3, 10 )\n",
    "tmp4 = genSphericalData( d, n, mu4, 1 )\n",
    "tmp5 = genSphericalData( d, n, mu5, 1 )\n",
    "X = np.vstack( (tmp1, tmp2, tmp3, tmp4, tmp5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = getFigure( 8, 8 )\n",
    "plot2D( X, fig, size = 50, color = 'b', marker = 'o' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Can you implement the k-means algorithm to cluster this dataset? Visualize your output. [10 points] \n",
    "\n",
    "(b) Implement k-means++ to initialize cluster centers usefully. [5 points]\n",
    "\n",
    "(c) What value of k gives you the best clustering? Are you happy with the quality of the clustering? [5 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) I'm going to say that we want to be able to do better than this. So I want you to kernelize your k-means algorithm with a Gaussian kernel. Visualize the clustering output of your kernel k-means algorithm [15 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Expectation-Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw how to use EM to learn parameters for Gaussian mixture models last week. Specifically, for a GMM described by the set of parameters $\\{\\pi_k, \\mu_k, \\Sigma_k \\}_{k=1}^K$, we saw that the E-step boils down to figuring out the expected assignment of clusters based on a responsibility judgment proportional to $\\pi_k~N(\\mu_k, \\Sigma_k)$, given curent parameter estimates, followed by using GDA MLE updates assuming the current expected assignment in the M-step to update parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Can you derive the E-step and M-step for an EM algorithm that would work for a Gaussian mixture model wherein the mixture weights $\\pi_k$ are known, and the covariances are restricted to be spherical, i.e. $\\Sigma_k = \\sigma^2_k I$? [20 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Implement this algorithm and show that it works on synthetic data with 3 clusters. If you are unable to derive the EM algorithm for part (a), implement the EM algorithm I showed in the class slides for the standard GMM (5 point penalty for taking this option) [15 points]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
