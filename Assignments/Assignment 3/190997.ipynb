{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS771A Assignment 3\n",
    "\\- Yash Gupta (190997)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the dataset and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc771a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of the columns of the dataset\n",
    "cols = ['variance', 'skewness', 'curtosis', 'entropy', 'class']\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f16f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "data = pd.read_csv('data_banknote_authentication.txt', names=cols)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the negative class label from 0 to -1\n",
    "data['class'].replace(0, -1, inplace=True)\n",
    "# data.loc[data['class'] == 0, 'class'] = -1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('class', axis=1)\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. (a)\n",
    "Code up the perceptron algorithm described on slide 7 of Lecture 15 using the same notation as in the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_algo(X, y, thresh):\n",
    "    w = np.zeros(4) # change\n",
    "    eta = 1\n",
    "    t = 0\n",
    "    t_mistake = 0\n",
    "    while t - t_mistake < thresh:\n",
    "        idx = np.random.choice(np.arange(len(X)))\n",
    "        X_n = X.loc[idx, :]\n",
    "        y_n = y[idx]\n",
    "        if y_n * np.dot(w, X_n) < 0:\n",
    "            w += eta * y_n * X_n\n",
    "            t_mistake = t\n",
    "        t += 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. (b)\n",
    "Write functions to make predictions using the algorithm for the banknotes dataset. Preprocess the dataset to handle missing and anomalous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, X):\n",
    "    y = np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        y[i] = 1 if np.dot(w, X.loc[i, :]) >= 0 else -1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_actual):\n",
    "    return (y_pred == y_actual).sum() / len(y_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. (c)\n",
    "Train the algorithm on the dataset using cross-validation and report cross-validated test set error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the rows of the dataframe\n",
    "data_shuffle = data.sample(frac=1, random_state=1)\n",
    "data_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing train-test split with 10% of the data as the test data\n",
    "train_size = int(0.9 * len(data))\n",
    "data_train = data_shuffle[:train_size].reset_index(drop=True)\n",
    "data_test = data_shuffle[train_size:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data):\n",
    "    data_shuffle = data.sample(frac=1)\n",
    "    data_shuffle\n",
    "    train_size = int(0.9 * len(data))\n",
    "    data_train = data_shuffle[:train_size].reset_index(drop=True)\n",
    "    data_val = data_shuffle[train_size:].reset_index(drop=True)\n",
    "    return data_train, data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "accuracy_dict = {}\n",
    "for k in range(5):\n",
    "    data_train_crossval, data_val = data_split(data_train)\n",
    "    X_train = data_train_crossval.drop('class', axis=1)\n",
    "    y_train = data_train_crossval['class']\n",
    "    X_val = data_val.drop('class', axis=1)\n",
    "    y_val = data_val['class']\n",
    "    for thresh in range(5, 30, 5):\n",
    "        if k == 0:\n",
    "            accuracy_dict[thresh] = 0\n",
    "        w = perceptron_algo(X_train, y_train, thresh)\n",
    "        y_pred = predict(w, X_val)\n",
    "        acc = accuracy(y_pred, y_val)\n",
    "        accuracy_dict[thresh] += acc\n",
    "best_acc = 0\n",
    "best_thresh = 0\n",
    "for thresh, acc in accuracy_dict.items():\n",
    "    acc /= 5\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_thresh = thresh\n",
    "print('The cross-validated accuracy is', best_acc, 'using a threshold of', best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. (d)\n",
    "Ensure you use a held out validation set and report F1 score on the held out set for your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop('class', axis=1)\n",
    "y_train = data_train['class']\n",
    "X_test = data_test.drop('class', axis=1)\n",
    "y_test = data_test['class']\n",
    "w = perceptron_algo(X_train, y_train, best_thresh)\n",
    "y_pred = predict(w, X_test)\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print('The test set accuracy is', acc, 'using a threshold of', best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = ((y_pred == y_test) & (y_test == 1)).sum()\n",
    "fn = ((y_pred != y_test) & (y_test == 1)).sum()\n",
    "fp = ((y_pred != y_test) & (y_test == -1)).sum()\n",
    "tn = ((y_pred == y_test) & (y_test == -1)).sum()\n",
    "p = tp / (tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "f1 = 2 * p * r / (p + r)\n",
    "print('F1 score on the test set is', f1, 'using a threshold of', best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. MCMC Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. (a)\n",
    "Write a function to calculate the Bayesian posterior probability given 50 new data samples drawn from a normal distribution with mean 10 and SD 5, assuming a normal prior with mean 25 and s.d. 5. Plot the pdfs of the prior, the likelihood and the posterior distributions. Explain how you derive the likelihood from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Distribution:\n",
    "$$ p(x | \\mu, \\sigma^2) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left( - \\frac{1}{2} \\left( \\frac{x - \\mu}{\\sigma} \\right)^2 \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal likelihood:\n",
    "$$ p(\\textbf{y} | \\mu, \\sigma^2) = \\prod_{n = 1}^N p(y_n | \\mu, \\sigma) = \\frac{1}{\\sigma^N (2 \\pi)^{\\frac{N}{2}}} \\exp \\left(- \\frac{1}{2 \\sigma^2} \\sum_{n = 1}^N \\left( y_n - \\mu \\right)^2 \\right) $$\n",
    "$$ = \\frac{1}{\\sigma^N (2 \\pi)^{\\frac{N}{2}}} \\exp \\left( - \\frac{1}{2 \\sigma^2} \\left( \\sum_n y_n^2 - 2 \\mu \\sum_n y_n + N \\mu^2 \\right) \\right) $$\n",
    "$$ = \\frac{1}{\\sigma^N (2 \\pi)^{\\frac{N}{2}}} \\exp \\left( - \\frac{1}{2 \\sigma^2} \\sum_n y_n^2 \\right) \\exp \\left( - \\frac{N}{2 \\sigma^2} \\left(- 2 \\mu \\overline{y} + \\mu^2 \\right) \\right) $$\n",
    "$$ = \\frac{1}{\\sigma^N (2 \\pi)^{\\frac{N}{2}}} \\exp \\left( - \\frac{1}{2 \\sigma^2} \\left( \\sum_n y_n^2 - N \\overline{y}^2 \\right) \\right) \\exp \\left( - \\frac{N}{2 \\sigma^2} (\\overline{y} - \\mu)^2 \\right) $$\n",
    "$$ \\propto p(\\overline{y} | \\mu, \\sigma^2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal prior:\n",
    "$$ p(\\mu | \\mu_0, \\sigma_0^2) = \\frac{1}{\\sigma_0 \\sqrt{2 \\pi}} \\exp \\left( - \\frac{1}{2} \\left( \\frac{\\mu - \\mu_0}{\\sigma_0} \\right)^2 \\right) $$\n",
    "<!-- $$ p(\\mu | \\mu_0, \\sigma_0^2) = p(\\mu | 25, 25) = \\frac{1}{5 \\sqrt{2 \\pi}} \\exp \\left( - \\frac{1}{2} \\left( \\frac{\\mu - 25}{5} \\right)^2 \\right) $$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior:\n",
    "$$ p(\\mu | \\textbf{y}) = \\frac{p(\\mu) p(\\textbf{y} | \\mu)}{p(\\textbf{y})} $$\n",
    "$$ \\propto p(\\mu) p(\\textbf{y} | \\mu) $$\n",
    "$$ \\propto p(\\mu) p(\\overline{y} | \\mu) $$\n",
    "<!-- $$ \\propto p(\\overline{y}) p(\\mu | \\overline{y}) $$\n",
    "$$ \\propto p(\\mu | \\overline{y}) $$ -->\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\left( \\frac{\\mu - \\mu_0}{\\sigma_0} \\right)^2 \\right) \\exp \\left( - \\frac{N}{2 \\sigma^2} (\\overline{y} - \\mu)^2 \\right) $$\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\left( \\left( \\frac{\\mu - \\mu_0}{\\sigma_0} \\right)^2 + \\left( \\frac{N}{\\sigma^2} (\\overline{y} - \\mu)^2 \\right) \\right) \\right) $$\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\left( \\frac{\\mu^2}{\\sigma_0^2} - \\frac{2 \\mu \\mu_0}{\\sigma_0^2} + \\frac{\\mu_0^2}{\\sigma_0^2} + \\frac{N \\overline{y}^2}{\\sigma^2} - \\frac{2 N \\overline{y} \\mu}{\\sigma^2} + \\frac{N \\mu^2}{\\sigma^2} \\right) \\right) $$\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\left( \\left( \\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2} \\right) \\mu^2 - 2 \\left( \\frac{\\mu_0}{\\sigma_0^2} + \\frac{N \\overline{y}}{\\sigma^2} \\right) \\mu + \\left( \\frac{\\mu_0^2}{\\sigma_0^2} + \\frac{N \\overline{y}^2}{\\sigma^2} \\right) \\right) \\right) $$\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\left( \\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2} \\right) \\left( \\mu^2 - 2 \\left( \\frac{\\frac{\\mu_0}{\\sigma_0^2} + \\frac{N \\overline{y}}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}} \\right) \\mu + \\frac{\\frac{\\mu_0^2}{\\sigma_0^2} + \\frac{N \\overline{y}^2}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}} \\right) \\right) $$\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\left( \\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2} \\right) \\left( \\mu - \\frac{\\frac{\\mu_0}{\\sigma_0^2} + \\frac{N \\overline{y}}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}} \\right)^2 \\right) $$\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\frac{\\left( \\mu - \\frac{\\frac{\\mu_0}{\\sigma_0^2} + \\frac{N \\overline{y}}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}} \\right)^2}{\\left( \\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2} \\right)^{-1}} \\right) $$\n",
    "\n",
    "<!-- where\n",
    "$$ p(\\textbf{y}) = \\int p(\\mu) p(\\textbf{y} | \\mu) d \\theta $$\n",
    "\n",
    "Hence, \n",
    "$$ p(\\mu | \\textbf{y}) = \\frac{\\frac{1}{5 \\sqrt{2 \\pi}} \\exp \\left(- \\frac{1}{2} \\left( \\frac{\\mu - 25}{5} \\right)^2 \\right) \\frac{1}{\\sigma^N (2 \\pi)^{\\frac{N}{2}}} \\exp \\left( - \\frac{1}{2 \\sigma^2} \\sum_{n = 1}^N \\left( y_n - \\mu \\right)^2 \\right)}{p(\\textbf{y})} $$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, Posterior:\n",
    "$$ p(\\mu | \\textbf{y}) \\sim N(\\mu_1, \\sigma_1^2) = \\frac{1}{\\sigma_1 \\sqrt{2 \\pi}} \\exp \\left( - \\frac{1}{2} \\left( \\frac{\\mu - \\mu_1}{\\sigma_1} \\right)^2 \\right) $$\n",
    "where\n",
    "$$ \\mu_1 = \\frac{\\frac{\\mu_0}{\\sigma_0^2} + \\frac{N \\overline{y}}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}} $$\n",
    "$$ \\sigma_1^2 = \\left( \\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2} \\right)^{-1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(x, mu=0, sigma=1):\n",
    "    exp = -(((x - mu) / sigma) ** 2) / 2\n",
    "    p = np.exp(exp) / (sigma * np.sqrt(2 * np.pi))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(mu, y, sigma=1):\n",
    "    l = 1\n",
    "    for y_n in y:\n",
    "        l *= normal(y_n, mu, sigma)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(mu, y, mu0=0, sigma0=1, sigma=1):\n",
    "    n = len(y)\n",
    "    y_bar = 0\n",
    "    for y_n in y:\n",
    "        y_bar += y_n\n",
    "    y_bar /= n\n",
    "\n",
    "    num_mu1 = (mu0 / (sigma0 ** 2)) + (n * y_bar / (sigma ** 2))\n",
    "    den_mu1 = (1 / (sigma0 ** 2)) + (n / (sigma ** 2))\n",
    "    mu1 = num_mu1 / den_mu1\n",
    "\n",
    "    sigma1_sq_inv = (1 / (sigma0 ** 2)) + (n / (sigma ** 2))\n",
    "    sigma1_sq = 1 / sigma1_sq_inv\n",
    "    sigma1 = np.sqrt(sigma1_sq)\n",
    "\n",
    "    return normal(mu, mu1, sigma1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 100, 100)\n",
    "y = np.random.normal(10, 5, 50)\n",
    "plt.plot(x, normal(x, 25, 5))\n",
    "plt.plot(x, likelihood(x, y, 5)) #\n",
    "plt.plot(x, posterior(x, y, 25, 5, 5)) #\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. (b)\n",
    "Implement the Metropolis algorithm from the lecture slides to estimate the posterior distribution given the same prior and data and show that it converges to the analytic posterior by plotting a histogram of samples from the distribution alongside the analytic posterior distribution. Assume whatever SD (width) you want for the proposal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(prior, likelihood, y, mu0=0, sigma0=1, sigma=1):\n",
    "    hist = [0.0]\n",
    "    sd = 1\n",
    "    mu_last = 0.0\n",
    "    for i in range(1000):\n",
    "        mu_curr = np.random.normal(mu_last, sd)\n",
    "        r = (prior(mu_curr, mu0, sigma0) * likelihood(mu_curr, y, sigma)) / (prior(mu_last, mu0, sigma0) * likelihood(mu_last, y, sigma))\n",
    "        a = np.random.uniform(0, 1)\n",
    "        if r <= a:\n",
    "            mu_curr = mu_last\n",
    "        hist.append(mu_curr)\n",
    "        mu_last = mu_curr\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = metropolis_hastings(normal, likelihood, y, 25, 5, 5)\n",
    "plt.hist(hist)\n",
    "plt.plot(x, posterior(x, y, 25, 5, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. (c)\n",
    "How does the speed of convergence of the sampling depend on the proposal width? Is there an optimal proposal width that would work best? Demonstrate the consequences of using sub-optimal proposal width and terminating sampling too soon."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
