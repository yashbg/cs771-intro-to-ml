{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS771A Assignment 3\n",
    "\\- Yash Gupta (190997)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the dataset and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc771a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['variance', 'skewness', 'curtosis', 'entropy', 'class']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# names of the columns of the dataset\n",
    "cols = ['variance', 'skewness', 'curtosis', 'entropy', 'class']\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f16f5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  class\n",
       "0      3.62160   8.66610   -2.8073 -0.44699      0\n",
       "1      4.54590   8.16740   -2.4586 -1.46210      0\n",
       "2      3.86600  -2.63830    1.9242  0.10645      0\n",
       "3      3.45660   9.52280   -4.0112 -3.59440      0\n",
       "4      0.32924  -4.45520    4.5718 -0.98880      0\n",
       "...        ...       ...       ...      ...    ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949      1\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179      1\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710      1\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230      1\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520      1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data\n",
    "data = pd.read_csv('data_banknote_authentication.txt', names=cols)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variance    0\n",
       "skewness    0\n",
       "curtosis    0\n",
       "entropy     0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  class\n",
       "0      3.62160   8.66610   -2.8073 -0.44699     -1\n",
       "1      4.54590   8.16740   -2.4586 -1.46210     -1\n",
       "2      3.86600  -2.63830    1.9242  0.10645     -1\n",
       "3      3.45660   9.52280   -4.0112 -3.59440     -1\n",
       "4      0.32924  -4.45520    4.5718 -0.98880     -1\n",
       "...        ...       ...       ...      ...    ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949      1\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179      1\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710      1\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230      1\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520      1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the negative class label from 0 to -1\n",
    "data['class'].replace(0, -1, inplace=True)\n",
    "# data.loc[data['class'] == 0, 'class'] = -1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('class', axis=1)\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. (a)\n",
    "Code up the perceptron algorithm described on slide 7 of Lecture 15 using the same notation as in the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_algo(X, y, thresh):\n",
    "    w = np.zeros(4) # change\n",
    "    eta = 1\n",
    "    t = 0\n",
    "    t_mistake = 0\n",
    "    while t - t_mistake < thresh:\n",
    "        idx = np.random.choice(np.arange(len(X)))\n",
    "        X_n = X.loc[idx, :]\n",
    "        y_n = y[idx]\n",
    "        if y_n * np.dot(w, X_n) < 0:\n",
    "            w += eta * y_n * X_n\n",
    "            t_mistake = t\n",
    "        t += 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. (b)\n",
    "Write functions to make predictions using the algorithm for the banknotes dataset. Preprocess the dataset to handle missing and anomalous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, X):\n",
    "    y = np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        y[i] = 1 if np.dot(w, X.loc[i, :]) >= 0 else -1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_actual):\n",
    "    return (y_pred == y_actual).sum() / len(y_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. (c)\n",
    "Train the algorithm on the dataset using cross-validation and report cross-validated test set error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>-3.55100</td>\n",
       "      <td>1.89550</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>-2.440900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1.31140</td>\n",
       "      <td>4.54620</td>\n",
       "      <td>2.293500</td>\n",
       "      <td>0.225410</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>-4.01730</td>\n",
       "      <td>-8.31230</td>\n",
       "      <td>12.454700</td>\n",
       "      <td>-1.437500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>-5.11900</td>\n",
       "      <td>6.64860</td>\n",
       "      <td>-0.049987</td>\n",
       "      <td>-6.520600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.62890</td>\n",
       "      <td>0.81322</td>\n",
       "      <td>1.627700</td>\n",
       "      <td>0.776270</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>3.49160</td>\n",
       "      <td>8.57090</td>\n",
       "      <td>-3.032600</td>\n",
       "      <td>-0.591820</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0.74521</td>\n",
       "      <td>3.63570</td>\n",
       "      <td>-4.404400</td>\n",
       "      <td>-4.141400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>-4.36670</td>\n",
       "      <td>6.06920</td>\n",
       "      <td>0.572080</td>\n",
       "      <td>-5.466800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2.04660</td>\n",
       "      <td>2.03000</td>\n",
       "      <td>2.176100</td>\n",
       "      <td>-0.083634</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>-2.31470</td>\n",
       "      <td>3.66680</td>\n",
       "      <td>-0.696900</td>\n",
       "      <td>-1.247400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness   curtosis   entropy  class\n",
       "1240  -3.55100   1.89550   0.186500 -2.440900      1\n",
       "703    1.31140   4.54620   2.293500  0.225410     -1\n",
       "821   -4.01730  -8.31230  12.454700 -1.437500      1\n",
       "1081  -5.11900   6.64860  -0.049987 -6.520600      1\n",
       "37     3.62890   0.81322   1.627700  0.776270     -1\n",
       "...        ...       ...        ...       ...    ...\n",
       "715    3.49160   8.57090  -3.032600 -0.591820     -1\n",
       "905    0.74521   3.63570  -4.404400 -4.141400      1\n",
       "1096  -4.36670   6.06920   0.572080 -5.466800      1\n",
       "235    2.04660   2.03000   2.176100 -0.083634     -1\n",
       "1061  -2.31470   3.66680  -0.696900 -1.247400      1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling the rows of the dataframe\n",
    "data_shuffle = data.sample(frac=1, random_state=1)\n",
    "data_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing train-test split with 10% of the data as the test data\n",
    "train_size = int(0.9 * len(data))\n",
    "data_train = data_shuffle[:train_size].reset_index(drop=True)\n",
    "data_test = data_shuffle[train_size:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data):\n",
    "    data_shuffle = data.sample(frac=1)\n",
    "    data_shuffle\n",
    "    train_size = int(0.9 * len(data))\n",
    "    data_train = data_shuffle[:train_size].reset_index(drop=True)\n",
    "    data_val = data_shuffle[train_size:].reset_index(drop=True)\n",
    "    return data_train, data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated accuracy is 0.435483870967742 using a threshold of 5\n"
     ]
    }
   ],
   "source": [
    "# cross-validation\n",
    "accuracy_dict = {}\n",
    "for k in range(5):\n",
    "    data_train_crossval, data_val = data_split(data_train)\n",
    "    X_train = data_train_crossval.drop('class', axis=1)\n",
    "    y_train = data_train_crossval['class']\n",
    "    X_val = data_val.drop('class', axis=1)\n",
    "    y_val = data_val['class']\n",
    "    for thresh in range(5, 30, 5):\n",
    "        if k == 0:\n",
    "            accuracy_dict[thresh] = 0\n",
    "        w = perceptron_algo(X_train, y_train, thresh)\n",
    "        y_pred = predict(w, X_val)\n",
    "        acc = accuracy(y_pred, y_val)\n",
    "        accuracy_dict[thresh] += acc\n",
    "best_acc = 0\n",
    "best_thresh = 0\n",
    "for thresh, acc in accuracy_dict.items():\n",
    "    acc /= 5\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_thresh = thresh\n",
    "print('The cross-validated accuracy is', best_acc, 'using a threshold of', best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. (d)\n",
    "Ensure you use a held out validation set and report F1 score on the held out set for your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test set accuracy is 0.45652173913043476 using a threshold of 5\n"
     ]
    }
   ],
   "source": [
    "X_train = data_train.drop('class', axis=1)\n",
    "y_train = data_train['class']\n",
    "X_test = data_test.drop('class', axis=1)\n",
    "y_test = data_test['class']\n",
    "w = perceptron_algo(X_train, y_train, best_thresh)\n",
    "y_pred = predict(w, X_test)\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print('The test set accuracy is', acc, 'using a threshold of', best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on the test set is 0.626865671641791 using a threshold of 5\n"
     ]
    }
   ],
   "source": [
    "tp = ((y_pred == y_test) & (y_test == 1)).sum()\n",
    "fn = ((y_pred != y_test) & (y_test == 1)).sum()\n",
    "fp = ((y_pred != y_test) & (y_test == -1)).sum()\n",
    "tn = ((y_pred == y_test) & (y_test == -1)).sum()\n",
    "p = tp / (tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "f1 = 2 * p * r / (p + r)\n",
    "print('F1 score on the test set is', f1, 'using a threshold of', best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. MCMC Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. (a)\n",
    "Write a function to calculate the Bayesian posterior probability given 50 new data samples drawn from a normal distribution with mean 10 and SD 5, assuming a normal prior with mean 25 and s.d. 5. Plot the pdfs of the prior, the likelihood and the posterior distributions. Explain how you derive the likelihood from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Distribution:\n",
    "$$ p(x | \\mu, \\sigma^2) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left( - \\frac{1}{2} \\left( \\frac{x - \\mu}{\\sigma} \\right)^2 \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal likelihood:\n",
    "$$ p(\\textbf{y} | \\mu, \\sigma^2) = \\prod_{n = 1}^N p(y_n | \\mu, \\sigma) = \\frac{1}{\\sigma^N (2 \\pi)^{\\frac{N}{2}}} \\exp \\left(- \\frac{1}{2 \\sigma^2} \\sum_{n = 1}^N \\left( y_n - \\mu \\right)^2 \\right) $$\n",
    "$$ = \\frac{1}{\\sigma^N (2 \\pi)^{\\frac{N}{2}}} \\exp \\left( - \\frac{1}{2 \\sigma^2} \\left( \\sum_n y_n^2 - 2 \\mu \\sum_n y_n + N \\mu^2 \\right) \\right) $$\n",
    "$$ = \\frac{1}{\\sigma^N (2 \\pi)^{\\frac{N}{2}}} \\exp \\left( - \\frac{1}{2 \\sigma^2} \\sum_n y_n^2 \\right) \\exp \\left( - \\frac{N}{2 \\sigma^2} \\left(- 2 \\mu \\overline{y} + \\mu^2 \\right) \\right) $$\n",
    "$$ = \\frac{1}{\\sigma^N (2 \\pi)^{\\frac{N}{2}}} \\exp \\left( - \\frac{1}{2 \\sigma^2} \\left( \\sum_n y_n^2 - N \\overline{y}^2 \\right) \\right) \\exp \\left( - \\frac{N}{2 \\sigma^2} (\\overline{y} - \\mu)^2 \\right) $$\n",
    "$$ \\propto p(\\overline{y} | \\mu, \\sigma^2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal prior:\n",
    "$$ p(\\mu | \\mu_0, \\sigma_0^2) = \\frac{1}{\\sigma_0 \\sqrt{2 \\pi}} \\exp \\left( - \\frac{1}{2} \\left( \\frac{\\mu - \\mu_0}{\\sigma_0} \\right)^2 \\right) $$\n",
    "<!-- $$ p(\\mu | \\mu_0, \\sigma_0^2) = p(\\mu | 25, 25) = \\frac{1}{5 \\sqrt{2 \\pi}} \\exp \\left( - \\frac{1}{2} \\left( \\frac{\\mu - 25}{5} \\right)^2 \\right) $$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior:\n",
    "$$ p(\\mu | \\textbf{y}) = \\frac{p(\\mu) p(\\textbf{y} | \\mu)}{p(\\textbf{y})} $$\n",
    "$$ \\propto p(\\mu) p(\\textbf{y} | \\mu) $$\n",
    "$$ \\propto p(\\mu) p(\\overline{y} | \\mu) $$\n",
    "<!-- $$ \\propto p(\\overline{y}) p(\\mu | \\overline{y}) $$\n",
    "$$ \\propto p(\\mu | \\overline{y}) $$ -->\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\left( \\frac{\\mu - \\mu_0}{\\sigma_0} \\right)^2 \\right) \\exp \\left( - \\frac{N}{2 \\sigma^2} (\\overline{y} - \\mu)^2 \\right) $$\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\left( \\left( \\frac{\\mu - \\mu_0}{\\sigma_0} \\right)^2 + \\left( \\frac{N}{\\sigma^2} (\\overline{y} - \\mu)^2 \\right) \\right) \\right) $$\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\left( \\frac{\\mu^2}{\\sigma_0^2} - \\frac{2 \\mu \\mu_0}{\\sigma_0^2} + \\frac{\\mu_0^2}{\\sigma_0^2} + \\frac{N \\overline{y}^2}{\\sigma^2} - \\frac{2 N \\overline{y} \\mu}{\\sigma^2} + \\frac{N \\mu^2}{\\sigma^2} \\right) \\right) $$\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\left( \\left( \\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2} \\right) \\mu^2 - 2 \\left( \\frac{\\mu_0}{\\sigma_0^2} + \\frac{N \\overline{y}}{\\sigma^2} \\right) \\mu + \\left( \\frac{\\mu_0^2}{\\sigma_0^2} + \\frac{N \\overline{y}^2}{\\sigma^2} \\right) \\right) \\right) $$\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\left( \\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2} \\right) \\left( \\mu^2 - 2 \\left( \\frac{\\frac{\\mu_0}{\\sigma_0^2} + \\frac{N \\overline{y}}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}} \\right) \\mu + \\frac{\\frac{\\mu_0^2}{\\sigma_0^2} + \\frac{N \\overline{y}^2}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}} \\right) \\right) $$\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\left( \\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2} \\right) \\left( \\mu - \\frac{\\frac{\\mu_0}{\\sigma_0^2} + \\frac{N \\overline{y}}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}} \\right)^2 \\right) $$\n",
    "$$ \\propto \\exp \\left( - \\frac{1}{2} \\frac{\\left( \\mu - \\frac{\\frac{\\mu_0}{\\sigma_0^2} + \\frac{N \\overline{y}}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}} \\right)^2}{\\left( \\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2} \\right)^{-1}} \\right) $$\n",
    "\n",
    "<!-- where\n",
    "$$ p(\\textbf{y}) = \\int p(\\mu) p(\\textbf{y} | \\mu) d \\theta $$\n",
    "\n",
    "Hence, \n",
    "$$ p(\\mu | \\textbf{y}) = \\frac{\\frac{1}{5 \\sqrt{2 \\pi}} \\exp \\left(- \\frac{1}{2} \\left( \\frac{\\mu - 25}{5} \\right)^2 \\right) \\frac{1}{\\sigma^N (2 \\pi)^{\\frac{N}{2}}} \\exp \\left( - \\frac{1}{2 \\sigma^2} \\sum_{n = 1}^N \\left( y_n - \\mu \\right)^2 \\right)}{p(\\textbf{y})} $$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, Posterior:\n",
    "$$ p(\\mu | \\textbf{y}) \\sim N(\\mu_1, \\sigma_1^2) = \\frac{1}{\\sigma_1 \\sqrt{2 \\pi}} \\exp \\left( - \\frac{1}{2} \\left( \\frac{\\mu - \\mu_1}{\\sigma_1} \\right)^2 \\right) $$\n",
    "where\n",
    "$$ \\mu_1 = \\frac{\\frac{\\mu_0}{\\sigma_0^2} + \\frac{N \\overline{y}}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}} $$\n",
    "$$ \\sigma_1^2 = \\left( \\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2} \\right)^{-1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(x, mu=0, sigma=1):\n",
    "    exp = -(((x - mu) / sigma) ** 2) / 2\n",
    "    p = np.exp(exp) / (sigma * np.sqrt(2 * np.pi))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(mu, y, sigma=1):\n",
    "    l = 1\n",
    "    for y_n in y:\n",
    "        l *= normal(y_n, mu, sigma)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(mu, y, mu0=0, sigma0=1, sigma=1):\n",
    "    n = len(y)\n",
    "    y_bar = 0\n",
    "    for y_n in y:\n",
    "        y_bar += y_n\n",
    "    y_bar /= n\n",
    "\n",
    "    num_mu1 = (mu0 / (sigma0 ** 2)) + (n * y_bar / (sigma ** 2))\n",
    "    den_mu1 = (1 / (sigma0 ** 2)) + (n / (sigma ** 2))\n",
    "    mu1 = num_mu1 / den_mu1\n",
    "\n",
    "    sigma1_sq_inv = (1 / (sigma0 ** 2)) + (n / (sigma ** 2))\n",
    "    sigma1_sq = 1 / sigma1_sq_inv\n",
    "    sigma1 = np.sqrt(sigma1_sq)\n",
    "\n",
    "    return normal(mu, mu1, sigma1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0, 50, 1000)\n",
    "y = np.random.normal(10, 5, 50)\n",
    "plt.plot(x, normal(x, 25, 5))\n",
    "plt.plot(x, likelihood(x, y, 5)) #\n",
    "plt.plot(x, posterior(x, y, 25, 5, 5)) #\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. (b)\n",
    "Implement the Metropolis algorithm from the lecture slides to estimate the posterior distribution given the same prior and data and show that it converges to the analytic posterior by plotting a histogram of samples from the distribution alongside the analytic posterior distribution. Assume whatever SD (width) you want for the proposal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(prior, likelihood, y, mu0=0, sigma0=1, sigma=1):\n",
    "    hist = [0.0]\n",
    "    sd = 1\n",
    "    mu_last = 0.0\n",
    "    for i in range(1000):\n",
    "        mu_curr = np.random.normal(mu_last, sd)\n",
    "        r = (prior(mu_curr, mu0, sigma0) * likelihood(mu_curr, y, sigma)) / (prior(mu_last, mu0, sigma0) * likelihood(mu_last, y, sigma))\n",
    "        a = np.random.uniform(0, 1)\n",
    "        if r <= a:\n",
    "            mu_curr = mu_last\n",
    "        hist.append(mu_curr)\n",
    "        mu_last = mu_curr\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = metropolis_hastings(normal, likelihood, y, 25, 5, 5)\n",
    "x = np.linspace(0, 25, 500)\n",
    "plt.hist(hist, 50)\n",
    "plt.plot(x, 240 * posterior(x, y, 25, 5, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. (c)\n",
    "How does the speed of convergence of the sampling depend on the proposal width? Is there an optimal proposal width that would work best? Demonstrate the consequences of using sub-optimal proposal width and terminating sampling too soon."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
